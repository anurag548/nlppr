{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmXiG9kaOQFq"
      },
      "source": [
        "#Viterbi Algorithm\n",
        "import numpy as np\n",
        "\n",
        "def viterbi(states,prob_dict,initial_probs,_obs):\n",
        "  '''\n",
        "  Parameters:\n",
        "  1. states - list of hidden states ['Hot','Cold','Mild']\n",
        "  2. prob_dict - tuple that contains the dictionaries transition_probs and emission probs\n",
        "     example of transition_probs:\n",
        "     transition_probs = {'Hot|Hot':0.6,'Hot|Mild':0.3,'Hot|Cold':0.1,\n",
        "                         'Mild|Hot':0.4,'Mild|Mild':0.3,'Mild|Cold':0.2,\n",
        "                         'Cold|Hot':0.1,'Cold|Mild':0.4,'Cold|Cold':0.5}\n",
        "\n",
        "     example of emission_probs:\n",
        "     emission_probs =   {'CasualWear|Hot':0.8,'CasualWear|Mild':0.19,'CasualWear|Cold':0.01,\n",
        "                         'SemiCasualWear|Hot':0.5,'SemiCasualWear|Mild':0.4,'SemiCasualWear|Cold':0.1,\n",
        "                         'ApparelWear|Hot':0.01,'ApparelWear|Mild':0.2,'ApparelWear|Cold':0.79}\n",
        "\n",
        "  3. _obs - list of a sequence of observable states\n",
        "     example of _obs = ['ApparelWear','CasualWear', 'CasualWear', 'SemiCasualWear']\n",
        "\n",
        "  Returns:\n",
        "  1. cache - required for backtracking to achieve the best hidden state sequence\n",
        "  2. viterbi_list - the index of the max value of this list is required to initiate backward pass of the Viterbi Algorithm\n",
        "  '''\n",
        "  # Generate list of sequences\n",
        "  n = len(states)\n",
        "  transition_probs = prob_dict[0]\n",
        "  emission_probs = prob_dict[1]\n",
        "  viterbi_list = []\n",
        "  cache = {}\n",
        "\n",
        "  for state in states:\n",
        "    viterbi_list.append(initial_probs[state]*emission_probs[_obs[0]+\"|\"+state])\n",
        "\n",
        "  for i,ob in enumerate(_obs):\n",
        "    if i==0: continue\n",
        "    temp_list = [None]*n\n",
        "    for j,state in enumerate(states):\n",
        "      x = -1\n",
        "      for k,prob in enumerate(viterbi_list):\n",
        "        val = prob*transition_probs[state+\"|\"+states[k]]*emission_probs[ob+\"|\"+state]\n",
        "        if (x<val):\n",
        "          x = val\n",
        "          cache[str(i)+\"-\"+state] = [states[k],val]\n",
        "      temp_list[j]= x\n",
        "    viterbi_list = [x for x in temp_list]\n",
        "\n",
        "\n",
        "  return cache,viterbi_list\n",
        "\n",
        "def viterbi_backward(states,cache,viterbi_list):\n",
        "  '''\n",
        "  Parameters:\n",
        "\n",
        "  To be used by passing (states , return values of Viterbi Algorithm) as parameters\n",
        "\n",
        "  1. cache - dictionary that stores state information of algorithm\n",
        "     example of cache:\n",
        "     {'1-Hot': ['Cold', 0.015800000000000005], '1-Mild': ['Cold', 0.02528000000000001], '1-Cold': ['Cold', 0.015800000000000005], '2-Hot': ['Hot', 0.007584000000000002], '2-Mild': ['Mild', 0.0014409600000000007], '2-Cold': ['Mild', 0.00010112000000000005]}\n",
        "\n",
        "  2. viterbi_list - list of numeric values (one corresponding to each state)\n",
        "\n",
        "  Returns:\n",
        "  1. best_sequence - list of predicted hidden states\n",
        "     example of best_sequence:\n",
        "     best_sequence = ['Hot','Cold','Cold']...\n",
        "\n",
        "  2. best_sequence_breakdown - list of probabilities at each stage (used for debugging)\n",
        "     example of best_sequence_breakdown:\n",
        "     best_sequence_breakdown = [0.5832000000000002, 0.4199040000000001, 0.3023308800000001]\n",
        "  '''\n",
        "  num_states = len(states)\n",
        "  n = len(cache)//num_states\n",
        "  best_sequence = []\n",
        "  best_sequence_breakdown=[]\n",
        "  x = states[np.argmax(np.asarray(viterbi_list))]\n",
        "  best_sequence.append(x)\n",
        "\n",
        "  for i in range(n,0,-1):\n",
        "    val = cache[str(i)+'-'+x][1]\n",
        "    x = cache[str(i)+'-'+x][0]\n",
        "    best_sequence = [x] + best_sequence\n",
        "    best_sequence_breakdown = [val]+best_sequence_breakdown\n",
        "\n",
        "  return best_sequence,best_sequence_breakdown\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS TAGGING"
      ],
      "metadata": {
        "id": "U2CzQE4e5uHQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vFzuK_zZi6V",
        "outputId": "e51e7ff9-9005-4d41-a732-d2a42f1b45d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#POS TAGGING\n",
        "def get_probs_ex1():\n",
        "  # transition probabilities\n",
        "  transition_probs = {'H|H':0.6,'H|M':0.3,'H|C':0.1,\n",
        "                      'M|H':0.4,'M|M':0.3,'M|C':0.2,\n",
        "                      'C|H':0.1,'C|M':0.4,'C|C':0.5}\n",
        "\n",
        "  # emission probabilities (CW-Casual Wear , SW-Semi Casual Wear , AW - Apparel)\n",
        "  emission_probs =   {'CW|H':0.8,'CW|M':0.19,'CW|C':0.01,\n",
        "                      'SW|H':0.5,'SW|M':0.4,'SW|C':0.1,\n",
        "                      'AW|H':0.01,'AW|M':0.2,'AW|C':0.79}\n",
        "\n",
        "  return transition_probs,emission_probs\n",
        "\n",
        "#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@\n",
        "\n",
        "# hidden states\n",
        "states1 = ['H','M','C']\n",
        "\n",
        "# set of observations\n",
        "obs = ['AW','SW','CW']\n",
        "\n",
        "# initial state probability distribution (our priors)\n",
        "initial_probs1 = {'H':0.3,'M':0.3,'C':0.4}\n",
        "\n",
        "# Generate list of sequences\n",
        "sequence_length,sequences,best_sequence,sequence_scores = initializeSequences(states1,get_probs_ex1(),initial_probs1,obs)\n",
        "\n",
        "print(\"Initial Distributions\")\n",
        "print(initial_probs1)\n",
        "\n",
        "transition_probs, emission_probs = get_probs_ex1()\n",
        "\n",
        "print(\"\\nTransition Probabilities\")\n",
        "pretty_print_probs(transition_probs)\n",
        "\n",
        "print(\"\\nEmission Probabilities\")\n",
        "pretty_print_probs(emission_probs)\n",
        "\n",
        "print(\"\\nScores\")\n",
        "# Display sequence scores\n",
        "for i in range(len(sequences)):\n",
        "    print(\"Sequence:%10s,Score:%0.4f\" % (sequences[i],sequence_scores[i]))\n",
        "\n",
        "# The best sequence for the given observation (obs) and initial chances of the hidden states (initial_probs)\n",
        "best_seq_n = np.argmax(sequence_scores)\n",
        "print(\"\\nBest Sequence:\",sequences[best_seq_n],best_sequence)\n",
        "print()\n",
        "cache,l = viterbi(states1,get_probs_ex1(),initial_probs1,obs)\n",
        "\n",
        "print(\"Path generated by viterbi algorithm by reducing computation...\",cache,sep=\"\\n\")\n",
        "print()\n",
        "print(\"Finding the best hidden sequence from the path generated by viterbi algorithm...\")\n",
        "print(viterbi_backward(states1,cache,l),np.max(np.asarray(l)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Distributions\n",
            "{'H': 0.3, 'M': 0.3, 'C': 0.4}\n",
            "\n",
            "Transition Probabilities\n",
            "+--------+-----+-----+-----+\n",
            "| rows   |   C |   M |   H |\n",
            "|--------+-----+-----+-----|\n",
            "| C      | 0.5 | 0.4 | 0.1 |\n",
            "| M      | 0.2 | 0.3 | 0.4 |\n",
            "| H      | 0.1 | 0.3 | 0.6 |\n",
            "+--------+-----+-----+-----+\n",
            "\n",
            "Emission Probabilities\n",
            "+--------+------+------+------+\n",
            "| rows   |    C |    M |    H |\n",
            "|--------+------+------+------|\n",
            "| CW     | 0.01 | 0.19 | 0.8  |\n",
            "| SW     | 0.1  | 0.4  | 0.5  |\n",
            "| AW     | 0.79 | 0.2  | 0.01 |\n",
            "+--------+------+------+------+\n",
            "\n",
            "Scores\n",
            "Sequence:['H', 'H', 'H'],Score:0.0004\n",
            "Sequence:['H', 'H', 'M'],Score:0.0001\n",
            "Sequence:['H', 'H', 'C'],Score:0.0000\n",
            "Sequence:['H', 'M', 'H'],Score:0.0001\n",
            "Sequence:['H', 'M', 'M'],Score:0.0000\n",
            "Sequence:['H', 'M', 'C'],Score:0.0000\n",
            "Sequence:['H', 'C', 'H'],Score:0.0000\n",
            "Sequence:['H', 'C', 'M'],Score:0.0000\n",
            "Sequence:['H', 'C', 'C'],Score:0.0000\n",
            "Sequence:['M', 'H', 'H'],Score:0.0043\n",
            "Sequence:['M', 'H', 'M'],Score:0.0007\n",
            "Sequence:['M', 'H', 'C'],Score:0.0000\n",
            "Sequence:['M', 'M', 'H'],Score:0.0017\n",
            "Sequence:['M', 'M', 'M'],Score:0.0004\n",
            "Sequence:['M', 'M', 'C'],Score:0.0000\n",
            "Sequence:['M', 'C', 'H'],Score:0.0002\n",
            "Sequence:['M', 'C', 'M'],Score:0.0001\n",
            "Sequence:['M', 'C', 'C'],Score:0.0000\n",
            "Sequence:['C', 'H', 'H'],Score:0.0076\n",
            "Sequence:['C', 'H', 'M'],Score:0.0012\n",
            "Sequence:['C', 'H', 'C'],Score:0.0000\n",
            "Sequence:['C', 'M', 'H'],Score:0.0061\n",
            "Sequence:['C', 'M', 'M'],Score:0.0014\n",
            "Sequence:['C', 'M', 'C'],Score:0.0001\n",
            "Sequence:['C', 'C', 'H'],Score:0.0013\n",
            "Sequence:['C', 'C', 'M'],Score:0.0006\n",
            "Sequence:['C', 'C', 'C'],Score:0.0001\n",
            "\n",
            "Best Sequence: ['C', 'H', 'H'] [0.31600000000000006, 0.015800000000000005, 0.007584000000000002]\n",
            "\n",
            "Path generated by viterbi algorithm by reducing computation...\n",
            "{'1-H': ['C', 0.015800000000000005], '1-M': ['C', 0.02528000000000001], '1-C': ['C', 0.015800000000000005], '2-H': ['H', 0.007584000000000002], '2-M': ['M', 0.0014409600000000007], '2-C': ['M', 0.00010112000000000005]}\n",
            "\n",
            "Finding the best hidden sequence from the path generated by viterbi algorithm...\n",
            "(['C', 'H', 'H'], [0.015800000000000005, 0.007584000000000002]) 0.007584000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLzgAscgGO_8"
      },
      "source": [
        "In the above example, initial probabilities of it being a hot day, cold day or a mild day were equal. But since the observable sequence (`obs`) was `['CW','CW','CW']`, therefore our HMM predicted that the three days would have been `['H', 'H', 'H']`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkhvP8qhGM4V",
        "outputId": "957b7382-3096-4577-acc5-6c659e9e9253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Example 2 (Simple Part of speech tagging)\n",
        "def get_probs_ex2():\n",
        "  transition_probs = {'Noun|Noun':0.1,'Noun|Verb':0.1,'Noun|Determiner':0.8,\n",
        "                      'Verb|Noun':0.8,'Verb|Verb':0.1,'Verb|Determiner':0.1,\n",
        "                      'Determiner|Noun':0.1,'Determiner|Verb':0.8,'Determiner|Determiner':0.1}\n",
        "  emission_probs = {'Bob|Noun':0.9,'ate|Noun':0.05,'the|Noun':0.05,'fruit|Noun':0.9,\\\n",
        "                    'Bob|Verb':0.05,'ate|Verb':0.9,'the|Verb':0.05,'fruit|Verb':0.05,\\\n",
        "                    'Bob|Determiner':0.05,'ate|Determiner':0.05,'the|Determiner':0.9,'fruit|Determiner':0.05}\n",
        "  return transition_probs,emission_probs\n",
        "\n",
        "#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@#@\n",
        "\n",
        "# generate new sequences\n",
        "states2 = ['Noun','Verb','Determiner']\n",
        "\n",
        "initial_probs2 = {'Noun':0.9,'Verb':0.05,'Determiner':0.05}\n",
        "\n",
        "transition_probs, emission_probs = get_probs_ex2()\n",
        "\n",
        "print(\"Initial Distributions\")\n",
        "print(initial_probs2)\n",
        "print(\"\\nTransition Probabilities\")\n",
        "pretty_print_probs(transition_probs)\n",
        "print(\"\\nEmission Probabilities\")\n",
        "pretty_print_probs(emission_probs)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Distributions\n",
            "{'Noun': 0.9, 'Verb': 0.05, 'Determiner': 0.05}\n",
            "\n",
            "Transition Probabilities\n",
            "+------------+--------+--------------+--------+\n",
            "| rows       |   Noun |   Determiner |   Verb |\n",
            "|------------+--------+--------------+--------|\n",
            "| Noun       |    0.1 |          0.8 |    0.1 |\n",
            "| Determiner |    0.1 |          0.1 |    0.8 |\n",
            "| Verb       |    0.8 |          0.1 |    0.1 |\n",
            "+------------+--------+--------------+--------+\n",
            "\n",
            "Emission Probabilities\n",
            "+--------+--------+--------------+--------+\n",
            "| rows   |   Noun |   Determiner |   Verb |\n",
            "|--------+--------+--------------+--------|\n",
            "| the    |   0.05 |         0.9  |   0.05 |\n",
            "| Bob    |   0.9  |         0.05 |   0.05 |\n",
            "| fruit  |   0.9  |         0.05 |   0.05 |\n",
            "| ate    |   0.05 |         0.05 |   0.9  |\n",
            "+--------+--------+--------------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkM9Jp5dsdRu",
        "outputId": "fa58f3fe-e89d-4a16-adbc-6fe30caf3197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "obs = ['Bob','ate','the','fruit']\n",
        "\n",
        "# print results\n",
        "print(\"\\nScores\")\n",
        "\n",
        "# Generate list of sequences\n",
        "sequence_length,sequences,best_sequence,sequence_scores = initializeSequences(states2,get_probs_ex2(),initial_probs2,obs)\n",
        "\n",
        "# Display sequence scores\n",
        "# Total number of sequences are 3^4 = 81\n",
        "for i in range(len(sequences)):\n",
        "    print(\"Sequence:%-60s Score:%0.6f\" % (sequences[i],sequence_scores[i]))\n",
        "\n",
        "# Display the winning score\n",
        "best_seq_n = np.argmax(sequence_scores)\n",
        "print(\"\\nBest Sequence:\",sequences[best_seq_n],best_sequence)\n",
        "print()\n",
        "cache,l = viterbi(states2,get_probs_ex2(),initial_probs2,obs)\n",
        "print(\"Path generated by viterbi algorithm by reducing computation...\",cache,sep=\"\\n\")\n",
        "print()\n",
        "print(\"Finding the best hidden sequence from the path generated by viterbi algorithm...\")\n",
        "print(viterbi_backward(states2,cache,l),np.max(np.asarray(l)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scores\n",
            "Sequence:['Noun', 'Noun', 'Noun', 'Noun']                             Score:0.000002\n",
            "Sequence:['Noun', 'Noun', 'Noun', 'Verb']                             Score:0.000001\n",
            "Sequence:['Noun', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Noun', 'Noun', 'Verb', 'Noun']                             Score:0.000015\n",
            "Sequence:['Noun', 'Noun', 'Verb', 'Verb']                             Score:0.000001\n",
            "Sequence:['Noun', 'Noun', 'Verb', 'Determiner']                       Score:0.000006\n",
            "Sequence:['Noun', 'Noun', 'Determiner', 'Noun']                       Score:0.000262\n",
            "Sequence:['Noun', 'Noun', 'Determiner', 'Verb']                       Score:0.000002\n",
            "Sequence:['Noun', 'Noun', 'Determiner', 'Determiner']                 Score:0.000002\n",
            "Sequence:['Noun', 'Verb', 'Noun', 'Noun']                             Score:0.000262\n",
            "Sequence:['Noun', 'Verb', 'Noun', 'Verb']                             Score:0.000117\n",
            "Sequence:['Noun', 'Verb', 'Noun', 'Determiner']                       Score:0.000015\n",
            "Sequence:['Noun', 'Verb', 'Verb', 'Noun']                             Score:0.000262\n",
            "Sequence:['Noun', 'Verb', 'Verb', 'Verb']                             Score:0.000015\n",
            "Sequence:['Noun', 'Verb', 'Verb', 'Determiner']                       Score:0.000117\n",
            "Sequence:['Noun', 'Verb', 'Determiner', 'Noun']                       Score:0.302331\n",
            "Sequence:['Noun', 'Verb', 'Determiner', 'Verb']                       Score:0.002100\n",
            "Sequence:['Noun', 'Verb', 'Determiner', 'Determiner']                 Score:0.002100\n",
            "Sequence:['Noun', 'Determiner', 'Noun', 'Noun']                       Score:0.000015\n",
            "Sequence:['Noun', 'Determiner', 'Noun', 'Verb']                       Score:0.000006\n",
            "Sequence:['Noun', 'Determiner', 'Noun', 'Determiner']                 Score:0.000001\n",
            "Sequence:['Noun', 'Determiner', 'Verb', 'Noun']                       Score:0.000002\n",
            "Sequence:['Noun', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Noun', 'Determiner', 'Verb', 'Determiner']                 Score:0.000001\n",
            "Sequence:['Noun', 'Determiner', 'Determiner', 'Noun']                 Score:0.000262\n",
            "Sequence:['Noun', 'Determiner', 'Determiner', 'Verb']                 Score:0.000002\n",
            "Sequence:['Noun', 'Determiner', 'Determiner', 'Determiner']           Score:0.000002\n",
            "Sequence:['Verb', 'Noun', 'Noun', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Noun', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Verb', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Verb', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Verb', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Determiner', 'Noun']                       Score:0.000001\n",
            "Sequence:['Verb', 'Noun', 'Determiner', 'Verb']                       Score:0.000000\n",
            "Sequence:['Verb', 'Noun', 'Determiner', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Noun', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Noun', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Noun', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Verb', 'Noun']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Verb', 'Verb']                             Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Verb', 'Determiner']                       Score:0.000000\n",
            "Sequence:['Verb', 'Verb', 'Determiner', 'Noun']                       Score:0.000117\n",
            "Sequence:['Verb', 'Verb', 'Determiner', 'Verb']                       Score:0.000001\n",
            "Sequence:['Verb', 'Verb', 'Determiner', 'Determiner']                 Score:0.000001\n",
            "Sequence:['Verb', 'Determiner', 'Noun', 'Noun']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Noun', 'Verb']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Noun', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Verb', 'Noun']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Verb', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Determiner', 'Noun']                 Score:0.000006\n",
            "Sequence:['Verb', 'Determiner', 'Determiner', 'Verb']                 Score:0.000000\n",
            "Sequence:['Verb', 'Determiner', 'Determiner', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Noun', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Noun', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Noun', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Verb', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Verb', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Determiner', 'Noun']                 Score:0.000006\n",
            "Sequence:['Determiner', 'Noun', 'Determiner', 'Verb']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Noun', 'Determiner', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Noun', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Noun', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Noun', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Verb', 'Noun']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Verb', 'Verb']                       Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Verb', 'Determiner']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Verb', 'Determiner', 'Noun']                 Score:0.000117\n",
            "Sequence:['Determiner', 'Verb', 'Determiner', 'Verb']                 Score:0.000001\n",
            "Sequence:['Determiner', 'Verb', 'Determiner', 'Determiner']           Score:0.000001\n",
            "Sequence:['Determiner', 'Determiner', 'Noun', 'Noun']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Noun', 'Verb']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Noun', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Verb', 'Noun']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Verb', 'Verb']                 Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Verb', 'Determiner']           Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Determiner', 'Noun']           Score:0.000001\n",
            "Sequence:['Determiner', 'Determiner', 'Determiner', 'Verb']           Score:0.000000\n",
            "Sequence:['Determiner', 'Determiner', 'Determiner', 'Determiner']     Score:0.000000\n",
            "\n",
            "Best Sequence: ['Noun', 'Verb', 'Determiner', 'Noun'] [0.81, 0.5832, 0.4199040000000001, 0.30233088000000014]\n",
            "\n",
            "Path generated by viterbi algorithm by reducing computation...\n",
            "{'1-Noun': ['Noun', 0.004050000000000001], '1-Verb': ['Noun', 0.5832000000000002], '1-Determiner': ['Noun', 0.004050000000000001], '2-Noun': ['Verb', 0.002916000000000001], '2-Verb': ['Verb', 0.002916000000000001], '2-Determiner': ['Verb', 0.4199040000000001], '3-Noun': ['Determiner', 0.3023308800000001], '3-Verb': ['Determiner', 0.0020995200000000006], '3-Determiner': ['Determiner', 0.0020995200000000006]}\n",
            "\n",
            "Finding the best hidden sequence from the path generated by viterbi algorithm...\n",
            "(['Noun', 'Verb', 'Determiner', 'Noun'], [0.5832000000000002, 0.4199040000000001, 0.3023308800000001]) 0.3023308800000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O2bo1MIM76E"
      },
      "source": [
        "We have correctly tagged the part of speech in\n",
        "\n",
        "\n",
        "\n",
        "1. Bob - Noun\n",
        "\n",
        "2. ate - Verb\n",
        "\n",
        "3. the - Determiner\n",
        "\n",
        "4. fruit - Noun\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yks4wgyVIGKy",
        "outputId": "ed293010-380e-4be3-ab02-0c0a96e25f34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Data for part of speech tagging\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAT4jvSbIeqG"
      },
      "source": [
        "from nltk.corpus import treebank\n",
        "sentences = treebank.tagged_sents(tagset='universal')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElpHWw76KJFg"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1fJQAmAvb9-17J6gcdvUJHJGyy6Y-hctd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cukIa5iIqfr",
        "outputId": "da25d73b-d123-4acb-b1da-996dec652322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3914"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_52cHkDhOKBx",
        "outputId": "5e29df65-415f-4687-bcef-dded0a8cecd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tagged_sentence = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
        "print(\"Number of Tagged Sentences \",len(tagged_sentence))\n",
        "tagged_words=[tup for sent in tagged_sentence for tup in sent]\n",
        "print(\"Total Number of Tagged words\", len(tagged_words))\n",
        "vocab=set([word for word,tag in tagged_words])\n",
        "print(\"Vocabulary of the Corpus\",len(vocab))\n",
        "tags=set([tag for word,tag in tagged_words])\n",
        "print(\"Number of Tags in the Corpus \",len(tags))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Tagged Sentences  3914\n",
            "Total Number of Tagged words 100676\n",
            "Vocabulary of the Corpus 12408\n",
            "Number of Tags in the Corpus  12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmWVc-iFUGtw",
        "outputId": "0f394aad-b08d-4745-a519-ecaf8e04fe30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tags)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'X', 'NUM', 'VERB', 'ADV', 'ADJ', 'NOUN', 'CONJ', 'PRT', 'PRON', 'DET', 'ADP', '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqNSMjN5yamA"
      },
      "source": [
        "`transition_probs` is a dictionary that tells the probability of getting a particular tag as the next POS tag given that which tag had occured previously.\n",
        "\n",
        "Hence using `transition_probs` we get:\n",
        "> `P['next state'|'previous state']`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbDHzRnrf20P",
        "outputId": "4c3069fc-2618-46ec-b387-11343bf86959",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Generating Dictionary for our hidden states (Part of speech tags) - transition_probs\n",
        "import numpy as np\n",
        "states = list(tags)\n",
        "print(states)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['X', 'NUM', 'VERB', 'ADV', 'ADJ', 'NOUN', 'CONJ', 'PRT', 'PRON', 'DET', 'ADP', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "d68bf851-1033-4a87-9b61-c447b696b3d1",
        "id": "uOkpAbAxW1E4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Generating the martix for calculating transition_probs for the dataset\n",
        "\n",
        "tr_matrix = np.zeros((len(states),len(states)))\n",
        "\n",
        "for sentence in tagged_sentence:\n",
        "  for i in range(len(sentence)):\n",
        "    if i==0: continue\n",
        "    tr_matrix[states.index(sentence[i-1][1])][states.index(sentence[i][1])]+=1\n",
        "\n",
        "print(tr_matrix.astype(int))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 494   18 1354  170  112  410   68 1221  367  361  955 1082]\n",
            " [ 746  656   64   10  118 1252   48   96    5   11  124  414]\n",
            " [2954  310 2292 1110  884 1497   73  426  482 1822 1239  475]\n",
            " [  73  100 1093  252  411  100   22   45   48  218  376  432]\n",
            " [ 134  133   77   30  425 4474  108   69    4   31  497  415]\n",
            " [ 837  273 4240  490  350 7623 1229 1267  135  377 5100 6926]\n",
            " [  19   94  355  124  266  792    1   11  133  270  120   80]\n",
            " [  43  183 1291   32  273  796    7    6   58  326   66  138]\n",
            " [ 254   20 1329   93  200  573   14   34   21   26   62  111]\n",
            " [ 398  193  346  110 1788 5569    4    2   31   48   81  154]\n",
            " [ 342  618   82  133 1050 3173    8   14  679 3194  167  392]\n",
            " [ 229  915 1003  412  359 1467  482   23  486 1114  565  776]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68kh49mWgFYP",
        "outputId": "0e11d5c4-2b12-4203-fe66-ce4f8f7dd011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tr_matrix /= np.sum(tr_matrix,keepdims=True,axis=1)\n",
        "print(tr_matrix)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.47126437e-02 2.72232305e-03 2.04779189e-01 2.57108288e-02\n",
            "  1.69388990e-02 6.20084694e-02 1.02843315e-02 1.84664247e-01\n",
            "  5.55051422e-02 5.45977011e-02 1.44434362e-01 1.63641863e-01]\n",
            " [2.10496614e-01 1.85101580e-01 1.80586907e-02 2.82167043e-03\n",
            "  3.32957111e-02 3.53273138e-01 1.35440181e-02 2.70880361e-02\n",
            "  1.41083521e-03 3.10383747e-03 3.49887133e-02 1.16817156e-01]\n",
            " [2.17782365e-01 2.28546152e-02 1.68976703e-01 8.18342672e-02\n",
            "  6.51725155e-02 1.10365674e-01 5.38189325e-03 3.14066647e-02\n",
            "  3.55352403e-02 1.34326157e-01 9.13447361e-02 3.50191684e-02]\n",
            " [2.30283912e-02 3.15457413e-02 3.44794953e-01 7.94952681e-02\n",
            "  1.29652997e-01 3.15457413e-02 6.94006309e-03 1.41955836e-02\n",
            "  1.51419558e-02 6.87697161e-02 1.18611987e-01 1.36277603e-01]\n",
            " [2.09473191e-02 2.07909958e-02 1.20368923e-02 4.68969830e-03\n",
            "  6.64373925e-02 6.99390339e-01 1.68829139e-02 1.07863061e-02\n",
            "  6.25293106e-04 4.84602157e-03 7.76926684e-02 6.48741598e-02]\n",
            " [2.90151489e-02 9.46372240e-03 1.46982355e-01 1.69861684e-02\n",
            "  1.21329774e-02 2.64256248e-01 4.26040836e-02 4.39213783e-02\n",
            "  4.67986272e-03 1.30689500e-02 1.76794814e-01 2.40094291e-01]\n",
            " [8.38852097e-03 4.15011038e-02 1.56732892e-01 5.47461369e-02\n",
            "  1.17439294e-01 3.49668874e-01 4.41501104e-04 4.85651214e-03\n",
            "  5.87196468e-02 1.19205298e-01 5.29801325e-02 3.53200883e-02]\n",
            " [1.33581858e-02 5.68499534e-02 4.01056229e-01 9.94097546e-03\n",
            "  8.48089469e-02 2.47281765e-01 2.17458838e-03 1.86393290e-03\n",
            "  1.80180180e-02 1.01273687e-01 2.05032619e-02 4.28704567e-02]\n",
            " [9.28023383e-02 7.30727073e-03 4.85568140e-01 3.39788089e-02\n",
            "  7.30727073e-02 2.09353307e-01 5.11508951e-03 1.24223602e-02\n",
            "  7.67263427e-03 9.49945195e-03 2.26525393e-02 4.05553526e-02]\n",
            " [4.56212746e-02 2.21228794e-02 3.96607061e-02 1.26088950e-02\n",
            "  2.04951857e-01 6.38353966e-01 4.58505273e-04 2.29252636e-04\n",
            "  3.55341586e-03 5.50206327e-03 9.28473177e-03 1.76524530e-02]\n",
            " [3.47137637e-02 6.27283800e-02 8.32318311e-03 1.34997970e-02\n",
            "  1.06577345e-01 3.22066585e-01 8.12017864e-04 1.42103126e-03\n",
            "  6.89200162e-02 3.24198132e-01 1.69508729e-02 3.97888754e-02]\n",
            " [2.92427532e-02 1.16843315e-01 1.28080705e-01 5.26114162e-02\n",
            "  4.58434427e-02 1.87332397e-01 6.15502490e-02 2.93704508e-03\n",
            "  6.20610395e-02 1.42255140e-01 7.21491508e-02 9.90933470e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhCdGwXiiLYd"
      },
      "source": [
        "#Hence we get our transition matrix. Now we need to create the dictionary transition_probs\n",
        "\n",
        "def get_transition_probs(states,tr_matrix):\n",
        "  state_dict = {}\n",
        "  for i,state in enumerate(states):\n",
        "    state_dict[i]=state\n",
        "  transition_probs = {}\n",
        "  for i in range(tr_matrix.shape[0]):\n",
        "    for j in range(tr_matrix.shape[1]):\n",
        "      transition_probs[state_dict[j]+'|'+state_dict[i]] = tr_matrix[i][j]\n",
        "  return transition_probs"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leoaZRksGxFi"
      },
      "source": [
        "def get_tr_matrix(states,tagged_sentence):\n",
        "  tr_matrix = np.zeros((len(states),len(states)))\n",
        "  for sentence in tagged_sentence:\n",
        "    for i in range(len(sentence)):\n",
        "      if i==0: continue\n",
        "      tr_matrix[states.index(sentence[i-1][1])][states.index(sentence[i][1])]+=1\n",
        "  tr_matrix /= np.sum(tr_matrix,keepdims=True,axis=1)\n",
        "  return tr_matrix"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94QX9c1Dxi8G",
        "outputId": "0b255266-e0f2-41a6-cb84-2024ccffde5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Generating Dictionary for our observable states (words) - emission_probs\n",
        "vocab = sorted(list(vocab))\n",
        "em_matrix = np.zeros((len(vocab),len(states)))\n",
        "print(em_matrix.shape)\n",
        "\n",
        "for sentence in tagged_sentence:\n",
        "  for word,tag in sentence:\n",
        "    em_matrix[vocab.index(word)][states.index(tag)]+=1\n",
        "\n",
        "print(em_matrix.astype(int))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12408, 12)\n",
            "[[  0   0   0 ...   0   0   6]\n",
            " [  0   0   0 ...   0   0  16]\n",
            " [  0   0   0 ...   0   0 718]\n",
            " ...\n",
            " [  0   0   1 ...   0   0   0]\n",
            " [  0   0   0 ...   0   0   0]\n",
            " [  0   0   1 ...   0   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEJOJAXEIxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6f9ddd-c581-4986-ec79-d3b12df82796"
      },
      "source": [
        "sum_matrix = np.sum(em_matrix,keepdims=True,axis=0)\n",
        "em_matrix = np.divide(em_matrix, sum_matrix, out=np.zeros_like(em_matrix), where=sum_matrix!=0)\n",
        "print(em_matrix)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 5.12163892e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 1.36577038e-03]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 6.12889458e-02]\n",
            " ...\n",
            " [0.00000000e+00 0.00000000e+00 7.37245650e-05 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 7.37245650e-05 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEkQZx387z2X"
      },
      "source": [
        "#Hence we get our emission matrix. Now we need to create the dictionary transition_probs\n",
        "def get_emission_probs(states,vocab,em_matrix):\n",
        "  state_dict = {}\n",
        "  for i,state in enumerate(states):\n",
        "    state_dict[i]=state\n",
        "  emission_probs = {}\n",
        "  for i in range(em_matrix.shape[0]):\n",
        "    for j in range(em_matrix.shape[1]):\n",
        "      emission_probs[vocab[i]+'|'+state_dict[j]] = em_matrix[i][j]\n",
        "  return emission_probs"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zo9Ewk4F4no"
      },
      "source": [
        "def get_em_matrix(states,vocab,tagged_sentence):\n",
        "  vocab = sorted(list(vocab))\n",
        "  em_matrix = np.zeros((len(vocab),len(states)))\n",
        "  for sentence in tagged_sentence:\n",
        "    for word,tag in sentence:\n",
        "      em_matrix[vocab.index(word)][states.index(tag)]+=1\n",
        "  sum_matrix = np.sum(em_matrix,keepdims=True,axis=0)\n",
        "  em_matrix = np.divide(em_matrix, sum_matrix, out=np.zeros_like(em_matrix), where=sum_matrix!=0)\n",
        "  return em_matrix"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1c7JQnBEwEv"
      },
      "source": [
        "def get_probs(states,vocab,tagged_sentence):\n",
        "  tr_matrix = get_tr_matrix(states,tagged_sentence)\n",
        "  em_matrix = get_em_matrix(states,vocab,tagged_sentence)\n",
        "  transition_probs = get_transition_probs(states,tr_matrix)\n",
        "  emission_probs = get_emission_probs(states,vocab,em_matrix)\n",
        "  return transition_probs,emission_probs"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkcTmfogIiaU"
      },
      "source": [
        "def get_initial_probs(states,tagged_sentence):\n",
        "  initial_list = [0]*len(states)\n",
        "  for sent in tagged_sentence:\n",
        "    tag = sent[0][1]\n",
        "    initial_list[states.index(tag)]+=1\n",
        "  initial_list = np.asarray(initial_list)\n",
        "  initial_list = initial_list/np.sum(initial_list,keepdims=True)\n",
        "  initial_probs = {}\n",
        "  for i,state in enumerate(states):\n",
        "    initial_probs[state] = initial_list[i]\n",
        "  return initial_probs"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBtB4_OaNYIj"
      },
      "source": [
        "def get_observation(sent):\n",
        "  ob = []\n",
        "  ob_tags = []\n",
        "  for word,tag in sent:\n",
        "    ob.append(word)\n",
        "    ob_tags.append(tag)\n",
        "  return ob,ob_tags"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B53o4VzoICNj"
      },
      "source": [
        "initial_probs = get_initial_probs(states,tagged_sentence)\n",
        "\n",
        "probs = get_probs(states,vocab,tagged_sentence)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASkd0bNQKvXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f88aa7f-3249-4956-9d33-2fec29253bdb"
      },
      "source": [
        "#Testing our Hidden Markov Model on the dataset\n",
        "import random\n",
        "ob = random.choice(tagged_sentence)\n",
        "obs,ob_tags = get_observation(ob)\n",
        "\n",
        "cache,l = viterbi(states,probs,initial_probs,obs)\n",
        "print(\"Finding the best hidden sequence from the path generated by viterbi algorithm...\")\n",
        "print()\n",
        "best_seq,_ = viterbi_backward(states,cache,l)\n",
        "print(\"TAGS ACHIEVED USING HIDDEN MARKOV MODEL-\",best_seq,sep=\"\\n\")\n",
        "print()\n",
        "print(\"ACTUAL TAGS-\",ob_tags,sep=\"\\n\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding the best hidden sequence from the path generated by viterbi algorithm...\n",
            "\n",
            "TAGS ACHIEVED USING HIDDEN MARKOV MODEL-\n",
            "['PRON', 'VERB', 'VERB', 'X', 'PRT', 'NOUN', 'PRT', 'NOUN', 'NOUN', '.', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'NOUN', '.']\n",
            "\n",
            "ACTUAL TAGS-\n",
            "['PRON', 'VERB', 'VERB', 'X', 'PRT', 'VERB', 'PRT', 'NOUN', 'NOUN', '.', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'NOUN', '.']\n"
          ]
        }
      ]
    }
  ]
}